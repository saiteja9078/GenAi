{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v9yXQxSzJQtM"
      },
      "outputs": [],
      "source": [
        "!pip install langchain google-search-results langchain_core google-generativeai langchain_google_genai langchain_community"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from getpass import getpass\n",
        "\n",
        "os.environ[\"LANGCHAIN_API_KEY\"] = os.getenv(\"LANGCHAIN_API_KEY\") or getpass(\"enter langsmith key\")\n",
        "\n",
        "# below should not be changed\n",
        "os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"\n",
        "os.environ[\"LANGCHAIN_ENDPOINT\"] = \"https://api.smith.langchain.com\"\n",
        "# you can change this as preferred\n",
        "os.environ[\"LANGCHAIN_PROJECT\"] = \"deepdive-to-agents\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7ag7qXiLMZOo",
        "outputId": "3d571321-b7e8-4a39-c1ad-4d4eb419e85d"
      },
      "execution_count": 2,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "enter langsmith key··········\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.prompts import ChatPromptTemplate,MessagesPlaceholder\n",
        "prompt_template = ChatPromptTemplate.from_messages([\n",
        "    (\"system\",(\n",
        "        \"You're a helpful assistant. When answering a user's question \"\n",
        "        \"you should first use one of the tools provided. After using a \"\n",
        "        \"tool the tool output will be provided in the \"\n",
        "        \"'scratchpad' below. If you have an answer in the \"\n",
        "        \"scratchpad you should not use any more tools and \"\n",
        "        \"instead answer directly to the user.\"\n",
        "    )),\n",
        "     MessagesPlaceholder(variable_name=\"chat_history\"),\n",
        "     (\"human\",\"{input}\"),\n",
        "     MessagesPlaceholder(variable_name=\"agent_scratchpad\")\n",
        "\n",
        "])"
      ],
      "metadata": {
        "id": "RRaLauiCMlWh"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "\n",
        "llm = ChatGoogleGenerativeAI(\n",
        "    temperature=0.0,\n",
        "    model=\"gemini-2.0-flash\",\n",
        "    api_key=getpass(\"Enter gemini api key: \")\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7-4kGNhkOxNE",
        "outputId": "7d61ae71-ffce-454b-c65c-8016b8bfdaba"
      },
      "execution_count": 11,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Enter gemini api key: ··········\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "llm.invoke(\"Hello\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3p1NCOzqQZTl",
        "outputId": "95ec11f6-47ce-449e-d5a8-96c1d7b5010a"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "AIMessage(content='Hello! How can I help you today?', additional_kwargs={}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'safety_ratings': []}, id='run--b4ae988d-3180-4639-be38-082c9603692d-0', usage_metadata={'input_tokens': 1, 'output_tokens': 10, 'total_tokens': 11, 'input_token_details': {'cache_read': 0}})"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.tools import tool\n",
        "\n",
        "@tool\n",
        "def add(x: float,y: float) -> float:\n",
        "  \"\"\"Add 'x' with 'y'.\"\"\"\n",
        "  return x+y\n",
        "@tool\n",
        "def subtract(x: float,y: float) -> float:\n",
        "  \"\"\"subtract 'y' from 'x'.\"\"\"\n",
        "  return x-y\n",
        "@tool\n",
        "def multiply(x: float,y: float) -> float:\n",
        "  \"\"\"multiply 'x' with 'y'.\"\"\"\n",
        "  return x*y\n",
        "@tool\n",
        "def exponentiate(x: float,y: float) -> float:\n",
        "  \"\"\"Raise 'x' to the power of 'y'.\"\"\"\n",
        "  return x**y\n"
      ],
      "metadata": {
        "id": "R8fMeZseQkyZ"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.runnables.base import RunnableSerializable\n",
        "\n",
        "tools=[add,multiply,exponentiate,subtract]\n",
        "agent : RunnableSerializable = (\n",
        "    {\n",
        "        \"input\": lambda x:x[\"input\"],\n",
        "        \"chat_history\": lambda x:x[\"chat_history\"],\n",
        "        \"agent_scratchpad\": lambda x: x.get(\"agent_scratchpad\",[])\n",
        "    }\n",
        "    | prompt_template\n",
        "    | llm.bind_tools(tools,tool_choice=\"any\")\n",
        ")"
      ],
      "metadata": {
        "id": "LUoffs6HSAls"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tool_call = agent.invoke({\n",
        "    \"input\":\"what is addition of 10 and 20\"\n",
        "    ,\"chat_history\":[]\n",
        "})"
      ],
      "metadata": {
        "id": "w0xfgR3LUO88"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tool_call"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k7ayiUjZVQde",
        "outputId": "32917371-df82-4564-ad30-e42790907c26"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "AIMessage(content='', additional_kwargs={'function_call': {'name': 'add', 'arguments': '{\"y\": 20.0, \"x\": 10.0}'}}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'safety_ratings': []}, id='run--6605adb4-1a4f-48cf-b007-cffc4e454128-0', tool_calls=[{'name': 'add', 'args': {'y': 20.0, 'x': 10.0}, 'id': '966a60da-c94e-4157-8a74-e7ceed022ab9', 'type': 'tool_call'}], usage_metadata={'input_tokens': 147, 'output_tokens': 5, 'total_tokens': 152, 'input_token_details': {'cache_read': 0}})"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "name2tool = {tool.name:tool.func for tool in tools}\n",
        "name2tool"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BbMX1VrAVS9f",
        "outputId": "50417fe8-013b-4390-9e21-d455ca950b5f"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'add': <function __main__.add(x: float, y: float) -> float>,\n",
              " 'multiply': <function __main__.multiply(x: float, y: float) -> float>,\n",
              " 'exponentiate': <function __main__.exponentiate(x: float, y: float) -> float>,\n",
              " 'subtract': <function __main__.subtract(x: float, y: float) -> float>}"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tool_exec_content = name2tool[tool_call.tool_calls[0][\"name\"]](\n",
        "    **tool_call.tool_calls[0][\"args\"]\n",
        ")"
      ],
      "metadata": {
        "id": "9l99bd6kVwlu"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tool_exec_content"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MTte4K7GWP3D",
        "outputId": "a0fe5b00-7d55-4806-f400-6bfa79d6b991"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "30.0"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###This is our answer and tool execution logic we feed this back into llm via scratchpad_placeholder along with tool_call_id"
      ],
      "metadata": {
        "id": "PF2pMosVYLVK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.messages import ToolMessage\n",
        "\n",
        "tool_message = ToolMessage(\n",
        "    content=f\"The {tool_call.tool_calls[0]['name']} tool returned {tool_exec_content}\",\n",
        "    tool_call_id = tool_call.tool_calls[0][\"id\"]\n",
        ")\n",
        "out = agent.invoke({\n",
        "    \"input\":\"what is addition of 10 and 20\",\n",
        "    \"chat_history\":[],\n",
        "    \"agent_scratchpad\":[tool_call,tool_message]\n",
        "})"
      ],
      "metadata": {
        "id": "0XTCsphKWRQ1"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "out"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DIhtyI-7Y41-",
        "outputId": "ac5e28cc-a0bd-4b5d-803f-fe6e2bf3a2bc"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "AIMessage(content='', additional_kwargs={'function_call': {'name': 'add', 'arguments': '{\"y\": 20.0, \"x\": 10.0}'}}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'safety_ratings': []}, id='run--9a40fb73-dd73-4aa1-a484-8cc7f50cdf28-0', tool_calls=[{'name': 'add', 'args': {'y': 20.0, 'x': 10.0}, 'id': '1e112f58-0eb8-406c-bef8-2ab64c8647ca', 'type': 'tool_call'}], usage_metadata={'input_tokens': 163, 'output_tokens': 5, 'total_tokens': 168, 'input_token_details': {'cache_read': 0}})"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#####Even after having the answer in the scratch pad the llm is calling tool , this is because we set tool_choice=\"any\" there are two ways to solve this\n",
        "\n",
        "\n",
        "1.   set tool_choice=\"auto\" to tell the llm to choose tool or provide final answer\n",
        "2.   create a final_answer tool\n",
        "\n"
      ],
      "metadata": {
        "id": "ULxnwdPVwR5u"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "first lets try first one"
      ],
      "metadata": {
        "id": "SKv2Bb8fw_w9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "agent: RunnableSerializable= (\n",
        "    {\n",
        "        \"input\":lambda x: x[\"input\"],\n",
        "        \"chat_history\":lambda x: x[\"chat_history\"],\n",
        "        \"agent_scratchpad\":lambda x: x.get(\"agent_scratchpad\",[])\n",
        "    }\n",
        "    | prompt_template\n",
        "    | llm.bind_tools(tools,tool_choice=\"auto\")\n",
        ")"
      ],
      "metadata": {
        "id": "Q2VYS-ymaALN"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Well repeat the process again , scratchpad is empty"
      ],
      "metadata": {
        "id": "Lg6AZ_zty814"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tool_call = agent.invoke({\"input\":\"what is the multiplication of 10 and 20\",\"chat_history\":[]})\n",
        "tool_call"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nPDl5kS1xl4l",
        "outputId": "cb193d93-c2a6-4dec-99a1-4d3fd333aadf"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "AIMessage(content='', additional_kwargs={'function_call': {'name': 'multiply', 'arguments': '{\"y\": 20.0, \"x\": 10.0}'}}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'safety_ratings': []}, id='run--227932b7-e6eb-4acd-b098-cc646b30e426-0', tool_calls=[{'name': 'multiply', 'args': {'y': 20.0, 'x': 10.0}, 'id': '3bd5fb63-da48-45fa-820e-032ebd040b96', 'type': 'tool_call'}], usage_metadata={'input_tokens': 148, 'output_tokens': 5, 'total_tokens': 153, 'input_token_details': {'cache_read': 0}})"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tool_output = name2tool[tool_call.tool_calls[0][\"name\"]](\n",
        "  **tool_call.tool_calls[0][\"args\"]\n",
        ")\n",
        "tool_message = ToolMessage(\n",
        "    content=f\"The {tool_call.tool_calls[0]['name']} tool returned {tool_output}\",\n",
        "    tool_call_id=tool_call.tool_calls[0][\"id\"]\n",
        ")\n",
        "out=agent.invoke({\n",
        "    \"input\":\"what is the multiplication of 10 and 20\",\n",
        "     \"chat_history\":[],\n",
        "    \"agent_scratchpad\":[tool_call,tool_message]\n",
        "})\n",
        "out"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5naj-JCWzUyc",
        "outputId": "530df80b-30e9-4d65-a0fd-2f8c4d8f6e56"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "AIMessage(content='The multiplication of 10 and 20 is 200.0.', additional_kwargs={}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'safety_ratings': []}, id='run--23ee94ad-1d9b-4ca1-bc48-3dda6815fc10-0', usage_metadata={'input_tokens': 165, 'output_tokens': 19, 'total_tokens': 184, 'input_token_details': {'cache_read': 0}})"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now lets check with final_answer\n"
      ],
      "metadata": {
        "id": "-Y--I0E4z_KA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "@tool\n",
        "def final_answer(answer: str, tools_used: list[str]) -> str:\n",
        "    \"\"\"Use this tool to provide a final answer to the user.\n",
        "    The answer should be in natural language, as this will be provided to the user directly.\n",
        "    The tools_used must include a list of tool names that were used within the 'scratchpad'.\n",
        "    \"\"\"\n",
        "    return {\n",
        "        \"answer\": answer,\n",
        "        \"tools_used\": tools_used\n",
        "    }"
      ],
      "metadata": {
        "id": "RFCb-VfFz6Rc"
      },
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tools=[final_answer,add,multiply,exponentiate,subtract]\n",
        "name2tool = {tool.name:tool.func for tool in tools}\n",
        "agent: RunnableSerializable= (\n",
        "    {\n",
        "        \"input\":lambda x: x[\"input\"],\n",
        "        \"chat_history\":lambda x: x[\"chat_history\"],\n",
        "        \"agent_scratchpad\":lambda x: x.get(\"agent_scratchpad\",[])\n",
        "    }\n",
        "    | prompt_template\n",
        "    | llm.bind_tools(tools,tool_choice=\"any\") #forcing llm to use the tool\n",
        ")"
      ],
      "metadata": {
        "id": "TQJZAOWp4CXE"
      },
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tool_call = agent.invoke({\"input\":\"what is the multiplication of 10 and 20\",\"chat_history\":[]})\n",
        "tool_call"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A_3pjSMP46IY",
        "outputId": "45b162f1-400b-4bf2-8c63-cbf5610b6dc2"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "AIMessage(content='', additional_kwargs={'function_call': {'name': 'multiply', 'arguments': '{\"y\": 20.0, \"x\": 10.0}'}}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'safety_ratings': []}, id='run--a00f8782-2660-45f0-b49f-e6012f7efaca-0', tool_calls=[{'name': 'multiply', 'args': {'y': 20.0, 'x': 10.0}, 'id': '4f80cb5e-3f38-41fd-8ebd-a022fa6d22c7', 'type': 'tool_call'}], usage_metadata={'input_tokens': 217, 'output_tokens': 5, 'total_tokens': 222, 'input_token_details': {'cache_read': 0}})"
            ]
          },
          "metadata": {},
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tool_output = name2tool[tool_call.tool_calls[0][\"name\"]](\n",
        "  **tool_call.tool_calls[0][\"args\"]\n",
        ")\n",
        "tool_message = ToolMessage(\n",
        "    content=f\"The {tool_call.tool_calls[0]['name']} tool returned {tool_output}\",\n",
        "    tool_call_id=tool_call.tool_calls[0][\"id\"]\n",
        ")\n",
        "out=agent.invoke({\n",
        "    \"input\":\"what is the multiplication of 10 and 20\",\n",
        "     \"chat_history\":[],\n",
        "    \"agent_scratchpad\":[tool_call,tool_message]\n",
        "})\n",
        "out.tool_calls[\"arguments\"]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4eIFaGVg5HQH",
        "outputId": "0923bb61-d63f-4817-d66c-10350489b20b"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "AIMessage(content='', additional_kwargs={'function_call': {'name': 'final_answer', 'arguments': '{\"answer\": \"The multiplication of 10 and 20 is 200.0\", \"tools_used\": [\"multiply\"]}'}}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'safety_ratings': []}, id='run--41ae9092-2137-4bd2-ba4b-cadcb7d81802-0', tool_calls=[{'name': 'final_answer', 'args': {'answer': 'The multiplication of 10 and 20 is 200.0', 'tools_used': ['multiply']}, 'id': '31f16988-b095-4725-a697-2fc6449afa73', 'type': 'tool_call'}], usage_metadata={'input_tokens': 234, 'output_tokens': 25, 'total_tokens': 259, 'input_token_details': {'cache_read': 0}})"
            ]
          },
          "metadata": {},
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "out.tool_calls[0][\"args\"]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vu_mxDvD5ND6",
        "outputId": "957359b1-8b85-4d3c-e43c-364e1f1a2ba1"
      },
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'answer': 'The multiplication of 10 and 20 is 200.0',\n",
              " 'tools_used': ['multiply']}"
            ]
          },
          "metadata": {},
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Building a custom Agent Execution loop"
      ],
      "metadata": {
        "id": "c7qeeMEr6g5X"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We've worked through each step of our agent code, but it doesn't run without us running every step. We must write a class to handle all the logic we just worked through."
      ],
      "metadata": {
        "id": "6ENUonki6J6H"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.messages import BaseMessage,HumanMessage,AIMessage\n",
        "\n",
        "class CustomAgentExecutor:\n",
        "  chat_history: list[BaseMessage]\n",
        "\n",
        "  def __init__(self,max_iteration:int =3):\n",
        "    self.chat_history=[]\n",
        "    self.max_iterations=max_iteration\n",
        "    self.agent: RunnableSerializable= (\n",
        "        {\n",
        "            \"input\":lambda x: x[\"input\"],\n",
        "            \"chat_history\":lambda x: x[\"chat_history\"],\n",
        "            \"agent_scratchpad\":lambda x: x.get(\"agent_scratchpad\",[])\n",
        "        }\n",
        "        | prompt_template\n",
        "        | llm.bind_tools(tools,tool_choice=\"any\") #forcing llm to use the tool again\n",
        "    )\n",
        "  def invoke(self,input:str) -> dict:\n",
        "    #invoking the agent but we do this in a loop untill we ge the final answer\n",
        "    count=0\n",
        "    agent_scratchpad=[]\n",
        "    while count<=self.max_iterations:\n",
        "      tool_call = self.agent.invoke({\n",
        "          \"input\":input,\n",
        "          \"chat_history\":self.chat_history,\n",
        "          \"agent_scratchpad\":agent_scratchpad\n",
        "      })\n",
        "      #add initial toolcall to agent scratchpad\n",
        "      agent_scratchpad.append(tool_call)\n",
        "      tool_name=tool_call.tool_calls[0][\"name\"] #assuming serial execution of tools\n",
        "      tool_call_id=tool_call.tool_calls[0][\"id\"]\n",
        "      tool_args = tool_call.tool_calls[0][\"args\"]\n",
        "      tool_output = name2tool[tool_name](**tool_args)\n",
        "      tool_message = ToolMessage(\n",
        "          content=f\"{tool_output}\",\n",
        "          tool_call_id=tool_call_id,\n",
        "      )\n",
        "      agent_scratchpad.append(tool_message)\n",
        "      count+=1\n",
        "      #add print to see intermediate steps\n",
        "      print(f\"{count} {tool_name}: {tool_args}\")\n",
        "\n",
        "      if tool_name==\"final_answer\":\n",
        "        break\n",
        "    final_answer=tool_output[\"answer\"]\n",
        "    self.chat_history.extend([\n",
        "        HumanMessage(content=input),\n",
        "        AIMessage(content=final_answer)\n",
        "    ])\n",
        "    return json.dumps(final_answer)"
      ],
      "metadata": {
        "id": "ixuvK2mn5bsp"
      },
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "agent_executor = CustomAgentExecutor(max_iteration=5)\n",
        "agent_executor.invoke(\n",
        "\"   A machine produces 15 units every hour. \\\n",
        "    After 3 hours, production is doubled by adding a second identical machine. \\\n",
        "    The machines then run together for another 4 hours. \\\n",
        "    Finally, the total production is squared to represent a performance score. \\\n",
        "    What is the final performance score?\"\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 137
        },
        "id": "6lxtkOeH7ka3",
        "outputId": "6cf8e5b3-815c-4747-c04d-6c8172ab7995"
      },
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1 multiply: {'y': 3.0, 'x': 15.0}\n",
            "2 multiply: {'y': 4.0, 'x': 15.0}\n",
            "3 add: {'y': 60.0, 'x': 60.0}\n",
            "4 add: {'y': 120.0, 'x': 45.0}\n",
            "5 exponentiate: {'y': 2.0, 'x': 165.0}\n",
            "6 final_answer: {'answer': 'The final performance score is 27225.', 'tools_used': ['multiply', 'add', 'exponentiate']}\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\"The final performance score is 27225.\"'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 72
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "agent_executor.chat_history"
      ],
      "metadata": {
        "id": "MImgr4xgD5qQ",
        "outputId": "ee01237c-c959-4934-b198-40ab852ffd52",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[HumanMessage(content='   A machine produces 15 units every hour.     After 3 hours, production is doubled by adding a second identical machine.     The machines then run together for another 4 hours.     Finally, the total production is squared to represent a performance score.     What is the final performance score?', additional_kwargs={}, response_metadata={}),\n",
              " AIMessage(content='The final performance score is 27225.', additional_kwargs={}, response_metadata={})]"
            ]
          },
          "metadata": {},
          "execution_count": 73
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "u-R4_M6KFiHZ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}