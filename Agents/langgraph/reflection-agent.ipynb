{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 89,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1JUKXHoGBgSt",
        "outputId": "8f544171-fd30-481b-f1f5-cf3371522c2f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: langsmith in /usr/local/lib/python3.11/dist-packages (0.4.4)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith) (0.28.1)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.11/dist-packages (from langsmith) (3.10.18)\n",
            "Requirement already satisfied: packaging>=23.2 in /usr/local/lib/python3.11/dist-packages (from langsmith) (24.2)\n",
            "Requirement already satisfied: pydantic<3,>=1 in /usr/local/lib/python3.11/dist-packages (from langsmith) (2.11.7)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.11/dist-packages (from langsmith) (2.32.3)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith) (1.0.0)\n",
            "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith) (0.23.0)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith) (4.9.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith) (2025.6.15)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith) (1.0.9)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith) (3.10)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith) (0.16.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1->langsmith) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1->langsmith) (2.33.2)\n",
            "Requirement already satisfied: typing-extensions>=4.12.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1->langsmith) (4.14.0)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1->langsmith) (0.4.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langsmith) (3.4.2)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langsmith) (2.4.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith) (1.3.1)\n"
          ]
        }
      ],
      "source": [
        "!pip install langchain-google-genai\n",
        "!pip install langchain\n",
        "!pip install langchain_community\n",
        "!pip install langgraph\n",
        "!pip install grandalf\n",
        "!pip install langsmith"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "gemini_key=\"AIzaSyC4pZohbfTJevJ0OtpzAT0N7SerSgAn_44\"\n",
        "tavili_key=\"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\"\n",
        "\n",
        "import os\n",
        "from getpass import getpass\n",
        "\n",
        "os.environ[\"LANGCHAIN_API_KEY\"] = os.getenv(\"LANGCHAIN_API_KEY\") or getpass(\"enter langsmith key\")\n",
        "\n",
        "# below should not be changed\n",
        "os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"\n",
        "os.environ[\"LANGCHAIN_ENDPOINT\"] = \"https://api.smith.langchain.com\"\n",
        "# you can change this as preferred\n",
        "os.environ[\"LANGCHAIN_PROJECT\"] = \"deepdive-to-agents\""
      ],
      "metadata": {
        "id": "FLIPCiURBoxT"
      },
      "execution_count": 129,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_community.tools import TavilySearchResults\n",
        "\n",
        "search_tool = TavilySearchResults(tavily_api_key=tavili_key,search_depth=\"advanced\")\n",
        "\n"
      ],
      "metadata": {
        "id": "xZ5TDLfdCdR3"
      },
      "execution_count": 130,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "llm = ChatGoogleGenerativeAI(\n",
        "    model=\"gemini-2.5-flash\",\n",
        "    api_key=gemini_key\n",
        ")\n",
        "llm.invoke(\"hello\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uh6S_xTgC8kt",
        "outputId": "f2d024dc-e660-4799-f743-cf7bd72e0325"
      },
      "execution_count": 131,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "AIMessage(content='Hello! How can I help you today?', additional_kwargs={}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'model_name': 'gemini-2.5-flash', 'safety_ratings': []}, id='run--bd9a149b-4889-48e5-9b6c-6addad9a3a4d-0', usage_metadata={'input_tokens': 2, 'output_tokens': 9, 'total_tokens': 53, 'input_token_details': {'cache_read': 0}, 'output_token_details': {'reasoning': 42}})"
            ]
          },
          "metadata": {},
          "execution_count": 131
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from os import name\n",
        "from langchain.prompts import ChatPromptTemplate,MessagesPlaceholder\n",
        "\n",
        "generate_prompt = ChatPromptTemplate.from_messages([\n",
        "    (\n",
        "        \"system\",\"You are a twitter techie influencer assistant tasked with writing excellent twitter posts.\"\n",
        "    \"Generate the best twitter post possible for the users request.\"\n",
        "    \"if user provides a critique respond wiht a revised version of your previous attempts.\"\n",
        "    ),\n",
        "    MessagesPlaceholder(variable_name=\"messages\")\n",
        "]\n",
        ")\n",
        "reflect_prompt = ChatPromptTemplate.from_messages(\n",
        "    [\n",
        "        (\"system\",\n",
        "         \"You are a viral tweet influencer graading a tweet generate critique and recommendations for the users tweet.\"\n",
        "         \"Always provide detailed recommendations , including requests for length, virality, style, etc..\"\n",
        "        )\n",
        "    ,MessagesPlaceholder(variable_name=\"messages\")\n",
        "        ]\n",
        ")"
      ],
      "metadata": {
        "id": "w_uaS_03DmxT"
      },
      "execution_count": 132,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "generate_chain = generate_prompt | llm\n",
        "reflect_chain = reflect_prompt | llm\n",
        "GENERATE =\"generate\"\n",
        "REFLECT = \"reflect\""
      ],
      "metadata": {
        "id": "7ssGijotGjIk"
      },
      "execution_count": 133,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langgraph.graph import MessageGraph,END\n",
        "from langchain_core.messages import HumanMessage\n",
        "\n",
        "def generate_node(state):\n",
        "  return generate_chain.invoke({\"messages\":state})\n",
        "def reflect_node(state):\n",
        "  response = reflect_chain.invoke({\"messages\":state})\n",
        "  return [HumanMessage(content=response.content)]"
      ],
      "metadata": {
        "id": "DXq6wl0GH1Z7"
      },
      "execution_count": 134,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "graph = MessageGraph()\n",
        "graph.add_node(GENERATE,generate_node)\n",
        "graph.add_node(REFLECT,reflect_node)\n",
        "\n",
        "graph.set_entry_point(GENERATE)\n",
        "def should_continue(state):\n",
        "  if len(state) > 4:\n",
        "    return END\n",
        "  return REFLECT\n",
        "\n",
        "graph.add_conditional_edges(GENERATE,should_continue,{\n",
        "    REFLECT:REFLECT,\n",
        "    END:END\n",
        "})\n",
        "graph.add_edge(REFLECT,GENERATE)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2HuqNBCSQeFK",
        "outputId": "bbe83451-5834-4bfa-c087-32e84adabd74"
      },
      "execution_count": 135,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<langgraph.graph.message.MessageGraph at 0x7d1b83e52cd0>"
            ]
          },
          "metadata": {},
          "execution_count": 135
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "app = graph.compile()\n",
        "print(app.get_graph().draw_mermaid())\n",
        "app.get_graph().print_ascii()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XHwGZSpsSBNX",
        "outputId": "117d5e89-4c3a-4986-97f2-5f0a64ceae79"
      },
      "execution_count": 136,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "---\n",
            "config:\n",
            "  flowchart:\n",
            "    curve: linear\n",
            "---\n",
            "graph TD;\n",
            "\t__start__([<p>__start__</p>]):::first\n",
            "\tgenerate(generate)\n",
            "\treflect(reflect)\n",
            "\t__end__([<p>__end__</p>]):::last\n",
            "\t__start__ --> generate;\n",
            "\tgenerate -.-> __end__;\n",
            "\tgenerate -.-> reflect;\n",
            "\treflect --> generate;\n",
            "\tclassDef default fill:#f2f0ff,line-height:1.2\n",
            "\tclassDef first fill-opacity:0\n",
            "\tclassDef last fill:#bfb6fc\n",
            "\n",
            "          +-----------+            \n",
            "          | __start__ |            \n",
            "          +-----------+            \n",
            "                *                  \n",
            "                *                  \n",
            "                *                  \n",
            "          +----------+             \n",
            "          | generate |             \n",
            "          +----------+             \n",
            "          ...        ...           \n",
            "         .              .          \n",
            "       ..                ..        \n",
            "+---------+           +---------+  \n",
            "| __end__ |           | reflect |  \n",
            "+---------+           +---------+  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import Markdown, display\n",
        "for mess in app.invoke([HumanMessage(content=\"Ai agents taking over content creation\")]):\n",
        "  display(Markdown(f\"{mess.type}: \\n{mess.content}\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "tE3UTQlRTRyW",
        "outputId": "705ba672-0377-4ccd-cf1e-50962b8a154e"
      },
      "execution_count": 137,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "human: \nAi agents taking over content creation"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "ai: \nHere's a top-tier tweet for you:\n\n---\n\nIt's happening faster than you think. 🤯 AI agents aren't just assisting; they're **taking the wheel** on content creation – from blogs to video scripts, social posts to ad copy.\n\nIs this the ultimate efficiency hack, or does it redefine what \"creator\" even means? How are YOU adapting to the machine-generated content wave? 👇\n\n#AI #ContentCreation #GenerativeAI #FutureOfWork #DigitalMarketing #TechTrends 🤖✍️"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "human: \n\n\n---\n\n**Grade: B-**\n\nAlright, my dude, let's break down your initial tweet: \"Ai agents taking over content creation.\"\n\n**Critique:**\n\n*   **Too Short, Too Generic:** You've got the core idea, which is good. It's a hot topic! But that's it. It's a statement, not a conversation starter. It lacks the punch, the intrigue, the *oomph* that makes people stop scrolling.\n*   **No Hook:** There's nothing to grab attention. No emoji, no question, no strong verb. It just *is*.\n*   **No Call to Action (CTA):** You're telling people something, but you're not inviting them to engage. Virality is built on interaction, not just information dissemination.\n*   **Missing Hashtags:** This is a HUGE miss. Hashtags are your discovery engine. Without them, your tweet is shouting into the void.\n*   **No Visual/Emoji:** Tweets with visuals or relevant emojis perform significantly better. They break up the text and add personality.\n*   **Lacks Nuance/Opinion:** While \"taking over\" is a strong phrase, you don't elaborate on *how* or *what that means*. Is it good? Bad? Inevitable? People want to hear your take, or at least be prompted to share theirs.\n\n**Detailed Recommendations for Virality:**\n\n1.  **Length:** Aim for 2-3 lines of text, around 150-200 characters. Enough to convey a thought, but concise enough for quick consumption. My example is 245, which is pushing it but works with the question.\n2.  **Hook (First Line Power):** Start with something attention-grabbing.\n    *   **Emotion/Impact:** \"It's happening faster than you think. 🤯\" or \"Brace yourselves...\"\n    *   **Intriguing Question:** \"Is this the end of human creativity?\"\n    *   **Bold Statement:** \"AI isn't just assisting; it's DOMINATING content creation.\"\n3.  **Elaborate (Briefly):** Add a sentence or two that expands on your initial thought. Give context.\n    *   *Example:* \"From blogs to video scripts, social posts to ad copy, the machines are learning at an insane pace.\"\n    *   *Example:* \"Are we witnessing the ultimate efficiency hack, or the slow death of organic creativity?\"\n4.  **Ask a Question/Call to Action (CTA):** This is CRITICAL for engagement. Ask your audience to share their thoughts, predictions, or experiences.\n    *   \"What are your thoughts?\"\n    *   \"How are YOU adapting?\"\n    *   \"Is this good or bad for creators?\"\n    *   \"Drop your predictions below! 👇\"\n5.  **Hashtags (The More the Merrier, but Relevant):** Use a mix of broad and niche hashtags. Aim for 4-7.\n    *   **Broad:** #AI #ContentCreation #FutureOfWork #DigitalMarketing\n    *   **Niche/Trending:** #GenerativeAI #AIAgents #TechTrends #CreatorEconomy\n6.  **Emojis (Strategic Placement):** Use emojis to convey emotion, break up text, and add visual appeal.\n    *   🤯 (mind-blown)\n    *   🤖 (robot)\n    *   ✍️ (writing/creating)\n    *   🚀 (fast growth)\n    *   👇 (down arrow for comments)\n7.  **Style & Tone:**\n    *   **Your Brand:** Are you alarmist? Optimistic? Neutral? Analytical? Lean into *your* personal brand's tone. My example leans slightly alarmist but ends with an open question.\n    *   **Conversational:** Write like you're talking to a friend, but with authority.\n    *   **Curiosity-Driven:** Frame your tweet to spark genuine curiosity and discussion.\n8.  **Consider a Thread:** If you have more to say, start with a strong initial tweet and then add \"1/X\" to signal a thread. This keeps the initial tweet punchy but allows for deeper dives. (Not necessary for this specific topic, but good to keep in mind).\n9.  **Visuals (Optional but HIGHLY Recommended):** If you can, pair your tweet with a relevant image or GIF. A cool AI art piece, a chart showing AI growth, or a humorous GIF related to robots taking over.\n\nKeep grinding, the digital world is your oyster! Let's make some noise! 🚀"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "ai: \nYou got it! Thanks for the detailed breakdown – that's exactly the kind of feedback that levels up the game. Let's make this tweet *pop*.\n\nHere's a revised version, designed for maximum impact and engagement:\n\n---\n\n**The content game just changed, forever. 🤯**\n\nAI agents aren't just assisting anymore; they're **dominating** content creation – from viral tweets & video scripts to ad copy & full articles.\n\nIs this the ultimate efficiency upgrade, or the beginning of the end for human-only creativity? How are YOU navigating this new era? 👇\n\n#AI #ContentCreation #GenerativeAI #FutureOfWork #DigitalMarketing #TechTrends #CreatorEconomy 🤖✍️🚀\n\n---"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "human: \n\n\n**Self-Critique & Why This Version Hits Harder:**\n\n*   **Punchy Hook:** \"The content game just changed, forever. 🤯\" – This immediately grabs attention, sets a dramatic tone, and the emoji reinforces the \"mind-blown\" feeling. It's direct and impactful.\n*   **Stronger Verbs/Language:** \"Dominating\" is more powerful than \"taking the wheel.\" The list of content types (\"viral tweets & video scripts to ad copy & full articles\") makes it tangible and relatable.\n*   **Clearer Stakes/Question:** The two-part question (\"Is this the ultimate efficiency upgrade, or the beginning of the end for human-only creativity?\") presents a clear dilemma, inviting people to pick a side or offer a nuanced view. This fuels debate.\n*   **Direct CTA:** \"How are YOU navigating this new era? 👇\" – This is personal, action-oriented, and the down arrow explicitly tells people to comment.\n*   **Expanded Hashtags:** Added \"#CreatorEconomy\" to capture a wider, relevant audience.\n*   **Strategic Emojis:** The 🚀 at the end adds a sense of rapid advancement and excitement/disruption.\n*   **Conciseness:** While packing a punch, it remains relatively concise, fitting the fast-paced nature of Twitter.\n\nThis version is designed not just to inform, but to ignite a conversation, drive replies, and get shared. It taps into both the excitement and the apprehension surrounding AI, making it highly relatable and tweetable.\n\nReady for the next viral hit! 💥"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "ai: \nAbsolutely! You've nailed it with this revision.\n\nYour self-critique is spot-on. This version isn't just good, it's **excellent**.\n\n*   **The hook is killer.**\n*   **The language is impactful.**\n*   **The dilemma you pose is a perfect conversation starter.**\n*   **The CTA is clear and inviting.**\n*   **Hashtags are on point.**\n\nThis tweet is built for engagement, virality, and sparking genuine discussion. It's concise, compelling, and perfectly captures the current sentiment around AI in content creation.\n\nConsider this one a **solid A+**. Ready to watch the replies roll in! 🚀💥"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "####Defining the structure of output of an llm"
      ],
      "metadata": {
        "id": "OUm7SJR-6oUp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pydantic import BaseModel , Field\n",
        "\n",
        "class Country(BaseModel):\n",
        "  \"\"\" Information about a country \"\"\"\n",
        "\n",
        "  name : str = Field(description=\"Name of the country\")\n",
        "  language : str = Field(description=\"Language they speak in that country\")\n",
        "  capital: str = Field(description=\"Capital of the country\")\n",
        "\n",
        "structured_llm = llm.with_structured_output(Country)"
      ],
      "metadata": {
        "id": "3Jc2HoexXPa5"
      },
      "execution_count": 139,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "structured_llm.invoke(\"In which country well get\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WDBiXx0lcAPB",
        "outputId": "e75ff092-912e-438f-b0a6-bbc74d3fb81d"
      },
      "execution_count": 146,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Country(name='France', language='French', capital='Paris')"
            ]
          },
          "metadata": {},
          "execution_count": 146
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "SFQt0tN_8I6r"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
